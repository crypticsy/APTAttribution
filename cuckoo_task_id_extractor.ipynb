{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and Prepare Task ID from HTML Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap the HTML data to extract the necessary information to prepare the task ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html_content, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Find all rows (<tr> elements) within the table body (<tbody>)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# These rows contain the task information we're interested in\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize empty lists to store extracted data: task IDs, filenames, and packages\u001b[39;00m\n\u001b[1;32m     15\u001b[0m task_ids \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# Open and read the HTML content from a file named 'summary_page.txt'\n",
    "with open('summary_page.txt') as file:\n",
    "    # Join all lines of the file into a single string, with newlines preserved\n",
    "    html_content = \"\\n\".join(file.readlines())\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "# This allows us to navigate the HTML structure and extract the required data\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all rows (<tr> elements) within the table body (<tbody>)\n",
    "# These rows contain the task information we're interested in\n",
    "rows = soup.find('tbody').find_all('tr')\n",
    "\n",
    "# Initialize empty lists to store extracted data: task IDs, filenames, and packages\n",
    "task_ids = []\n",
    "filenames = []\n",
    "packages = []\n",
    "\n",
    "# Loop through each row to extract the task id, filename, and package\n",
    "for row in rows:\n",
    "    # Extract the task ID from the 'data-task-id' attribute of the row\n",
    "    task_id = row.get('data-task-id')\n",
    "    \n",
    "    # Extract the filename from the third <td> element in the row\n",
    "    filename = row.find_all('td')[2].text.strip()\n",
    "    \n",
    "    # Extract the package type from the fourth <td> element in the row\n",
    "    package = row.find_all('td')[3].text.strip()\n",
    "    \n",
    "    # Append the extracted values to the respective lists\n",
    "    task_ids.append(task_id)\n",
    "    filenames.append(filename)\n",
    "    packages.append(package)\n",
    "\n",
    "# Create a DataFrame from the lists, with columns for Task ID, Filename, and Package\n",
    "df = pd.DataFrame({\n",
    "    'Task ID': task_ids,\n",
    "    'Filename': filenames,\n",
    "    'Package': packages\n",
    "})\n",
    "\n",
    "# Filter the DataFrame to exclude rows where the Package is '7z'\n",
    "# This removes unwanted rows from the DataFrame\n",
    "df = df[df.Package != '7z']\n",
    "\n",
    "# Output the filtered DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all filenames contain '@' and are unique\n",
    "assert df.Filename.apply(lambda x: int('@' in x)).sum() == df.shape[0]\n",
    "assert df.Filename.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Filename.duplicated(keep=False)].sort_values('Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='Filename', inplace=True, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame for further modifications\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Clean up the 'Filename' column by removing everything after and including the '@'\n",
    "df_clean['Filename'] = df_clean['Filename'].apply(lambda x: x if '@' not in x else x.split('@')[1].split('.')[0].strip() + '.zip')\n",
    "\n",
    "# Convert the 'Task ID' column from string to integer type\n",
    "df_clean['Task ID'] = df_clean['Task ID'].astype(int)\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load malware index and update with Task ID\n",
    "df_malware = pd.read_csv('malware.csv')\n",
    "\n",
    "for filename in df_clean['Filename']:\n",
    "    if df_malware[df_malware.file == filename].shape[0] != 1:\n",
    "        print(f\"Filename {filename} not found in malware.csv\")\n",
    "        continue\n",
    "    \n",
    "    df_malware.loc[df_malware['file'] == filename, 'cuckoo_id'] = df_clean.loc[df_clean['Filename'] == filename, 'Task ID'].values[0]\n",
    "\n",
    "print(\"The number of empty cuckoo_id is\", df_malware['cuckoo_id'].isnull().sum(), \"\\n\\n\")\n",
    "df_malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any extra files in the malware index\n",
    "df_clean[~df_clean['Filename'].isin(df_malware['file'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the records\n",
    "df_malware.to_csv('malware.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering only the missing APT to Download reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the malware index CSV\n",
    "df = pd.read_csv('malware.csv')\n",
    "\n",
    "# Filter records with a non-null cuckoo_id, sort by cuckoo_id, and convert it to int\n",
    "filtered = df[df['cuckoo_id'].notnull()].sort_values(by='cuckoo_id')\n",
    "filtered['cuckoo_id'] = filtered['cuckoo_id'].astype(int)\n",
    "\n",
    "# Print the count of samples with cuckoo_id and remaining samples per APT group\n",
    "print(\"The number of samples with cuckoo_id is: \", len(filtered))\n",
    "print(\"The number of remaining samples per APT group is: \", df.shape[0] - filtered.shape[0])\n",
    "\n",
    "# Check for and print the number of duplicates in cuckoo_id\n",
    "print('Duplicates: ', filtered.duplicated(subset=['cuckoo_id']).sum(), '\\n\\n')\n",
    "\n",
    "# Display the count of missing cuckoo_id values per APT group\n",
    "print(\"------ Missing -------\")\n",
    "display(df[df['cuckoo_id'].isnull()].apt.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_group = 'Gorgon Group'\n",
    "missing = df[df.apt == apt_group]\n",
    "missing[missing.cuckoo_id.isnull()].file.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# remove the missing directory with file\n",
    "if os.path.exists('missing'):\n",
    "  shutil.rmtree('missing')\n",
    "\n",
    "# create the missing directory\n",
    "os.mkdir('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_path = os.path.join(os.path.split(os.path.abspath('.'))[0], 'APTMalware', 'samples', apt_group)\n",
    "# copy missing files\n",
    "for file in missing[missing.cuckoo_id.isnull()].file.values:\n",
    "    dest_path = os.path.join(os.path.abspath('.'), 'missing', )\n",
    "    file_path = os.path.join(malware_path, file)\n",
    "    os.system(f\"cp '{file_path}' '{dest_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path of the current directory\n",
    "base_path = os.path.abspath('.')\n",
    "\n",
    "# Initialize a list to store downloaded Cuckoo task IDs\n",
    "downloaded_cuckoo_task = []\n",
    "\n",
    "# Loop through files and folders in the 'cuckoo' directory\n",
    "for filename in os.listdir(os.path.join(base_path, 'cuckoo')):\n",
    "    # Check if the item is a folder and it contains files\n",
    "    if os.path.isdir(os.path.join(base_path, 'cuckoo', filename)) and len(os.listdir(os.path.join(base_path, 'cuckoo', filename))) > 0:\n",
    "        # If so, add the folder name to the list of downloaded tasks\n",
    "        downloaded_cuckoo_task.append(filename)\n",
    "    else:\n",
    "        print(f\"Folder/File {filename} is empty\")\n",
    "\n",
    "# Filter the DataFrame to find tasks that have a cuckoo_id but haven't been downloaded yet\n",
    "df_to_download = filtered[~filtered.cuckoo_id.apply(lambda x: str(x)).isin(downloaded_cuckoo_task)]\n",
    "\n",
    "# Save these task IDs to a CSV file\n",
    "df_to_download.to_csv('cuckoo_task_ids_to_download.csv', index=False)\n",
    "\n",
    "# Display the DataFrame of tasks to be downloaded\n",
    "df_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_files = [x for x in downloaded_cuckoo_task if x not in filtered.cuckoo_id.apply(lambda x: str(x)).values]\n",
    "\n",
    "extra_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
